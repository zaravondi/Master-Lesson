{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import csv\n",
    "import time\n",
    "import itertools\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>itemName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "      <td>L.A. Confidential (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "      <td>Heavyweights (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "      <td>Jackie Brown (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "      <td>First Wives Club, The (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "      <td>Back to the Future (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "      <td>Sliver (1993)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "      <td>101 Dalmatians (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "      <td>Unforgiven (1992)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  itemId  rating  timestamp                      itemName\n",
       "0         196     242       3  881250949                  Kolya (1996)\n",
       "1         186     302       3  891717742      L.A. Confidential (1997)\n",
       "2          22     377       1  878887116           Heavyweights (1994)\n",
       "3         244      51       2  880606923    Legends of the Fall (1994)\n",
       "4         166     346       1  886397596           Jackie Brown (1997)\n",
       "...       ...     ...     ...        ...                           ...\n",
       "99995     880     476       3  880175444  First Wives Club, The (1996)\n",
       "99996     716     204       5  879795543     Back to the Future (1985)\n",
       "99997     276    1090       1  874795795                 Sliver (1993)\n",
       "99998      13     225       2  882399156         101 Dalmatians (1996)\n",
       "99999      12     203       3  879959583             Unforgiven (1992)\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading data movielens 100k\n",
    "data = pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp'])\n",
    "item_details = pd.read_csv('ml-100k/u.item', sep='|', names=['itemId', 'itemName'],usecols=range(2), encoding='latin-1')\n",
    "data.merge(item_details,on='itemId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['userId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId\n",
      "1      272\n",
      "2       62\n",
      "3       54\n",
      "4       24\n",
      "5      175\n",
      "      ... \n",
      "939     49\n",
      "940    107\n",
      "941     22\n",
      "942     79\n",
      "943    168\n",
      "Name: itemId, Length: 943, dtype: int64\n",
      "20\n",
      "737\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('userId').itemId.nunique())\n",
    "print(data.groupby('userId').itemId.nunique().min())#min 20\n",
    "print(data.groupby('userId').itemId.nunique().max())#max 737"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortItemsByTime(data):\n",
    "    sorted_users = []\n",
    "    for i, u in enumerate(data['userId'].unique()):\n",
    "        temp = data[data['userId'] == u]\n",
    "        temp = temp.sort_values('timestamp').reset_index()\n",
    "        temp.drop('index', axis=1, inplace=True)\n",
    "        sorted_users.append(temp)\n",
    "    return sorted_users\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>userId</th>\n",
       "      <th>itemId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96223</th>\n",
       "      <td>99995</td>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96224</th>\n",
       "      <td>99996</td>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96225</th>\n",
       "      <td>99997</td>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96226</th>\n",
       "      <td>99998</td>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96227</th>\n",
       "      <td>99999</td>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96228 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  userId  itemId  rating  timestamp\n",
       "0          0     196     242       3  881250949\n",
       "1          1     186     302       3  891717742\n",
       "2          2      22     377       1  878887116\n",
       "3          3     244      51       2  880606923\n",
       "4          4     166     346       1  886397596\n",
       "...      ...     ...     ...     ...        ...\n",
       "96223  99995     880     476       3  880175444\n",
       "96224  99996     716     204       5  879795543\n",
       "96225  99997     276    1090       1  874795795\n",
       "96226  99998      13     225       2  882399156\n",
       "96227  99999      12     203       3  879959583\n",
       "\n",
       "[96228 rows x 5 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexlist=[]\n",
    "for i, u in enumerate(data['userId'].unique()):\n",
    "    #print('i',i)\n",
    "    #print('index',data['userId'].index)\n",
    "    temp = data[data['userId'] == u]\n",
    "    #print('inex',temp.index)\n",
    "    temp = temp.sort_values('rating',ascending=False)\n",
    "    #print('inedsfsdfsdx',temp.index[0])\n",
    "    indexlist.append(temp.index[0])\n",
    "    indexlist.append(temp.index[1])\n",
    "    indexlist.append(temp.index[2])\n",
    "    indexlist.append(temp.index[3])\n",
    "                    \n",
    "data = data.drop(indexlist)\n",
    "data.reset_index()           \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('testdata.csv', mode='w') as file:\n",
    "        f_writer = csv.writer(file, delimiter=';')\n",
    "        f_writer.writerow(['userId', 'state'])\n",
    "        \n",
    "        for i, u in enumerate(data['userId'].unique()):\n",
    "            temp = data[data['userId'] == u]\n",
    "            temp = temp.sort_values('rating',ascending=False)\n",
    "            temp1=temp\n",
    "            temp1=temp1[0:4].reset_index()\n",
    "            temp1.drop('index', axis=1, inplace=True)\n",
    "            str_last=''\n",
    "            for j in range(4):\n",
    "                state_str=str(temp1['itemId'][j]) + '&' \n",
    "                rate_str=str(temp1['rating'][j]) +'|'\n",
    "                str_last +=  state_str  + rate_str \n",
    "\n",
    "            f_writer.writerow([u, str_last])     \n",
    "                                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieData():\n",
    "     def __init__(self,data):\n",
    "            self.data  = data\n",
    "            self.users = data['userId'].unique()\n",
    "            self.items = data['itemId'].unique()\n",
    "            self.histo = sortItemsByTime(data)\n",
    "            self.train = []\n",
    "            self.test  = []\n",
    "            \n",
    "     def divideTrainAndTestSet(self):\n",
    "        random.Random(42).shuffle(self.histo)\n",
    "        self.train = self.histo[:int((0.8 * len(self.histo)))]\n",
    "        self.test  = self.histo[int((0.8 * len(self.histo))):]\n",
    "        self.user_train = [h.iloc[0,0] for h in self.train]\n",
    "        self.user_test  = [h.iloc[0,0] for h in self.test] \n",
    "      \n",
    "        \n",
    "     def sample_histo(self, user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
    "        n = len(user_histo)\n",
    "        sep = int(action_ratio * n)\n",
    "        nb_sample = random.randint(1, max_samp_by_user)\n",
    "        if not nb_states:\n",
    "            nb_states = [min(random.randint(1, sep), max_state) for i in range(nb_sample)]\n",
    "        if not nb_actions:\n",
    "            nb_actions = [min(random.randint(1, n - sep), max_action) for i in range(nb_sample)]\n",
    "        assert len(nb_states) == len(nb_actions), 'Given array must have the same size'\n",
    "        states  = []\n",
    "        actions = []\n",
    "        # random bir ÅŸekilde state ve actionlar oluÅŸturuluyor.\n",
    "        for i in range(len(nb_states)):\n",
    "            sample_states = user_histo.iloc[0:sep].sample(nb_states[i]) #kiÅŸinin izledigi filmlerin yÃ¼zde 80 i states % 20 si action olarak\n",
    "            sample_actions = user_histo.iloc[-(n - sep):].sample(nb_actions[i])\n",
    "            sample_state = []\n",
    "            sample_action = []\n",
    "            for j in range(nb_states[i]):\n",
    "                row   = sample_states.iloc[j]\n",
    "                state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
    "                sample_state.append(state)\n",
    "            for j in range(nb_actions[i]):\n",
    "                row    = sample_actions.iloc[j]\n",
    "                action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
    "                sample_action.append(action)\n",
    "            states.append(sample_state)\n",
    "            actions.append(sample_action)\n",
    "        return states, actions  \n",
    "         \n",
    "     def write_csv(self, filename, histo_to_write):\n",
    "        history_length = 12\n",
    "        ra_length = 4 \n",
    "        delimiter=';'\n",
    "        action_ratio = 0.8\n",
    "        max_samp_by_user = 5\n",
    "        max_state = 100\n",
    "        max_action = 50\n",
    "        nb_states = [history_length]\n",
    "        nb_actions = [ra_length]\n",
    "    \n",
    "        with open(filename, mode='w') as file:\n",
    "          f_writer = csv.writer(file, delimiter=delimiter)\n",
    "          f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
    "          for user_histo in histo_to_write:\n",
    "            states, actions = self.sample_histo(user_histo, action_ratio, max_samp_by_user, max_state, max_action, nb_states, nb_actions)\n",
    "            for i in range(len(states)):\n",
    "              state_str   = '|'.join(states[i])\n",
    "              action_str  = '|'.join(actions[i])\n",
    "              n_state_str = state_str + '|' + action_str\n",
    "              f_writer.writerow([state_str, action_str, n_state_str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filePath):\n",
    "    data = pd.read_csv(filePath, sep=';')\n",
    "    for col in ['state', 'n_state', 'action_reward']:\n",
    "        data[col] = [np.array([[np.int(k) for k in ee.split('&')] for ee in e.split('|')]) for e in data[col]]\n",
    "    for col in ['state', 'n_state']:\n",
    "        data[col] = [np.array([e[0] for e in l]) for l in data[col]]\n",
    "    data['action'] = [[e[0] for e in l] for l in data['action_reward']]\n",
    "    data['reward'] = [tuple(e[1] for e in l) for l in data['action_reward']]\n",
    "    data.drop(columns=['action_reward'], inplace=True)\n",
    "    return data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embedding_size, tau, learning_rate, scope='actor'):\n",
    "        self.sess = sess\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.batch_size = batch_size\n",
    "        self.ra_length = ra_length\n",
    "        self.history_length = history_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.tau = tau\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scope = scope\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.action_weights, self.state, self.sequence_length = self._build_net('estimator_actor')\n",
    "            self.network_params = tf.trainable_variables()\n",
    "            self.target_action_weights, self.target_state, self.target_sequence_length = self._build_net('target_actor')\n",
    "            self.target_network_params = tf.trainable_variables()[len(self.network_params):] \n",
    "            self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
    "                                               for i in range(len(self.target_network_params))]\n",
    "            self.update_target_network_params = [self.target_network_params[i].assign(\n",
    "            tf.multiply(self.tau, self.network_params[i]) +\n",
    "            tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
    "            for i in range(len(self.target_network_params))]\n",
    "            self.action_gradients = tf.placeholder(tf.float32, [None, self.action_space_size])\n",
    "            gradients = tf.gradients(tf.reshape(self.action_weights, [self.batch_size, self.action_space_size], name='42222222222'),\n",
    "                               self.network_params,\n",
    "                               self.action_gradients)\n",
    "            params_gradients = list(map(lambda x: tf.div(x, self.batch_size * self.action_space_size), gradients))\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
    "              zip(params_gradients, self.network_params))\n",
    "    \n",
    "    def _build_net(self, scope):\n",
    "        def gather_last_output(data, seq_lens):\n",
    "            def cli_value(x, v):\n",
    "                y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
    "                x = tf.cast(x, tf.int64)\n",
    "                return tf.where(tf.greater(x, y), x, y)\n",
    "            batch_range = tf.range(tf.cast(tf.shape(data)[0], dtype=tf.int64), dtype=tf.int64)\n",
    "            tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
    "            indices = tf.stack([batch_range, tmp_end], axis=1)\n",
    "            return tf.gather_nd(data, indices)\n",
    "        with tf.variable_scope(scope):\n",
    "            state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
    "            state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
    "            sequence_length = tf.placeholder(tf.int32, [None], 'sequence_length')\n",
    "            cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.initializers.random_normal(),\n",
    "                                    bias_initializer=tf.zeros_initializer())\n",
    "            outputs, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
    "            last_output = gather_last_output(outputs, sequence_length)\n",
    "            x = tf.keras.layers.Dense(self.ra_length * self.embedding_size)(last_output)\n",
    "            action_weights = tf.reshape(x, [-1, self.ra_length, self.embedding_size])\n",
    "        return action_weights, state, sequence_length\n",
    "    def train(self, state, sequence_length, action_gradients):\n",
    "        self.sess.run(self.optimizer,\n",
    "                  feed_dict={\n",
    "                      self.state: state,\n",
    "                      self.sequence_length: sequence_length,\n",
    "                      self.action_gradients: action_gradients})\n",
    "    def predict(self, state, sequence_length):\n",
    "        #state length 1200\n",
    "        return self.sess.run(self.action_weights,\n",
    "                         feed_dict={\n",
    "                             self.state: state,\n",
    "                             self.sequence_length: sequence_length})\n",
    "    def predict_target(self, state, sequence_length):\n",
    "        return self.sess.run(self.target_action_weights,\n",
    "                         feed_dict={\n",
    "                             self.target_state: state,\n",
    "                             self.target_sequence_length: sequence_length})\n",
    "    def init_target_network(self):\n",
    "        self.sess.run(self.init_target_network_params)\n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)\n",
    "    def get_recommendation_list(self, ra_length, noisy_state, embeddings, target=False):\n",
    "        def get_score(weights, embedding, batch_size):\n",
    "            ret = np.dot(weights, embedding.T)\n",
    "            return ret\n",
    "        batch_size = noisy_state.shape[0]#batch_size 1\n",
    "        \n",
    "        method = self.predict_target if target else self.predict\n",
    "        weights = method(noisy_state, [ra_length] * batch_size)\n",
    "        scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n",
    "                             for embedding in embeddings.get_embedding_vector()]\n",
    "                             for k in range(ra_length)]\n",
    "                             for i in range(batch_size)])\n",
    "       \n",
    "        return np.array([[embeddings.get_embedding(np.argmax(scores[i][k]))\n",
    "                          for k in range(ra_length)]\n",
    "                          for i in range(batch_size)])\n",
    "                             \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_users=sortItemsByTime(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Critic():\n",
    "    def __init__(self, sess, state_space_size, action_space_size, history_length, embedding_size, tau, learning_rate, scope='critic'):\n",
    "        self.sess = sess\n",
    "        self.state_space_size = state_space_size\n",
    "        self.action_space_size = action_space_size\n",
    "        self.history_length = history_length\n",
    "        self.embedding_size = embedding_size\n",
    "        self.tau = tau\n",
    "        self.learning_rate = learning_rate\n",
    "        self.scope = scope\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.critic_Q_value, self.state, self.action, self.sequence_length = self._build_net('estimator_critic')\n",
    "            self.network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='estimator_critic')\n",
    "            self.target_Q_value, self.target_state, self.target_action, self.target_sequence_length = self._build_net('target_critic')\n",
    "            self.target_network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
    "            self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
    "                                               for i in range(len(self.target_network_params))]\n",
    "            self.update_target_network_params = [self.target_network_params[i].assign(\n",
    "                tf.multiply(self.tau, self.network_params[i]) +\n",
    "                tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
    "                for i in range(len(self.target_network_params))]\n",
    "            self.expected_reward = tf.placeholder(tf.float32, [None, 1])\n",
    "            self.loss = tf.reduce_mean(tf.squared_difference(self.expected_reward, self.critic_Q_value))\n",
    "            self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
    "            self.action_gradients = tf.gradients(self.critic_Q_value, self.action)\n",
    "    def _build_net(self, scope):\n",
    "        def gather_last_output(data, seq_lens):\n",
    "            def cli_value(x, v):\n",
    "                y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
    "                return tf.where(tf.greater(x, y), x, y)\n",
    "            this_range = tf.range(tf.cast(tf.shape(seq_lens)[0], dtype=tf.int64), dtype=tf.int64)\n",
    "            tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
    "            indices = tf.stack([this_range, tmp_end], axis=1)\n",
    "            return tf.gather_nd(data, indices)\n",
    "        with tf.variable_scope(scope):\n",
    "            state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
    "            state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
    "            action = tf.placeholder(tf.float32, [None, self.action_space_size], 'action')\n",
    "            sequence_length = tf.placeholder(tf.int64, [None], name='critic_sequence_length')\n",
    "            cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n",
    "                                    activation=tf.nn.relu,\n",
    "                                    kernel_initializer=tf.initializers.random_normal(),\n",
    "                                    bias_initializer=tf.zeros_initializer())\n",
    "            predicted_state, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
    "            predicted_state = gather_last_output(predicted_state, sequence_length)\n",
    "            inputs = tf.concat([predicted_state, action], axis=-1)\n",
    "            layer1 = tf.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
    "            layer2 = tf.layers.Dense(16, activation=tf.nn.relu)(layer1)\n",
    "            critic_Q_value = tf.layers.Dense(1)(layer2)\n",
    "            return critic_Q_value, state, action, sequence_length\n",
    "        \n",
    "    def train(self, state, action, sequence_length, expected_reward):\n",
    "        return self.sess.run([self.critic_Q_value, self.loss, self.optimizer],\n",
    "                         feed_dict={\n",
    "                             self.state: state,\n",
    "                             self.action: action,\n",
    "                             self.sequence_length: sequence_length,\n",
    "                             self.expected_reward: expected_reward})\n",
    "    def predict(self, state, action, sequence_length):\n",
    "        return self.sess.run(self.critic_Q_value,\n",
    "                         feed_dict={\n",
    "                             self.state: state,\n",
    "                             self.action: action,\n",
    "                             self.sequence_length: sequence_length})\n",
    "    def predict_target(self, state, action, sequence_length):\n",
    "        return self.sess.run(self.target_Q_value,\n",
    "                         feed_dict={\n",
    "                             self.target_state: state,\n",
    "                             self.target_action: action,\n",
    "                             self.target_sequence_length: sequence_length})\n",
    "    def get_action_gradients(self, state, action, sequence_length):\n",
    "        return np.array(self.sess.run(self.action_gradients,\n",
    "                         feed_dict={\n",
    "                             self.state: state,\n",
    "                             self.action: action,\n",
    "                             self.sequence_length: sequence_length})[0])\n",
    "    def init_target_network(self):\n",
    "        self.sess.run(self.init_target_network_params)\n",
    "    def update_target_network(self):\n",
    "        self.sess.run(self.update_target_network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings:\n",
    "    def __init__(self, item_embeddings):\n",
    "        self.item_embeddings = item_embeddings\n",
    "    def size(self):    \n",
    "        return self.item_embeddings.shape[1]\n",
    "    def get_embedding_vector(self):\n",
    "        return self.item_embeddings\n",
    "    def get_embedding(self, item_index):\n",
    "        return self.item_embeddings[item_index]\n",
    "    def embed(self, item_list):\n",
    "        return np.array([self.get_embedding(item) for item in item_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsInformation:\n",
    "  def  __init__(self, train_users, data):\n",
    "    self.train_users = train_users\n",
    "\n",
    "    #preprocess\n",
    "    self.data = data.sort_values(by=['timestamp'])\n",
    "    self.data['userId'] = self.data['userId'] - 1\n",
    "    self.data['itemId'] = self.data['itemId'] - 1\n",
    "    self.user_count = self.data['userId'].max() + 1\n",
    "    self.movie_count = self.data['itemId'].max() + 1\n",
    "    self.user_movies = {} #list of rated movies by each user\n",
    "    for userId in range(self.user_count):\n",
    "        self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()\n",
    "    self.m = self.model()\n",
    "\n",
    "  def model(self, hidden_layer_size=100):\n",
    "    m = Sequential()\n",
    "    m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(self.movie_count, activation='softmax'))\n",
    "    m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "  \n",
    "  def generate_input(self, user_id):\n",
    "    user_movies_count = len(self.user_movies[user_id])\n",
    "    #picking random movie\n",
    "    random_index = np.random.randint(0, user_movies_count-1) # -1 avoids taking the last movie\n",
    "    #generate 1 row each user's movie_count times column with zero initialize\n",
    "    target = np.zeros((1, self.movie_count))\n",
    "    #set 1 randomly chosen item id.\n",
    "    target[0][self.user_movies[user_id][random_index]] = 1\n",
    "    #setting context\n",
    "    #generate context 1 row ,user's movie_count times column\n",
    "    context = np.zeros((1, self.movie_count))\n",
    "    # randomly chosen item id's front + item id's after element list len\n",
    "    context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index+1:]] = 1\n",
    "    return context, target\n",
    "\n",
    "  def train(self, nb_epochs = 300, batch_size = 10000):      \n",
    "    '''\n",
    "    Trains the model from train_users's history information\n",
    "    '''\n",
    "    for i in range(nb_epochs):\n",
    "        print('%d/%d' % (i+1, nb_epochs))\n",
    "        batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]\n",
    "        X_train = np.array([b[0] for b in batch])\n",
    "        y_train = np.array([b[1] for b in batch])\n",
    "        self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)\n",
    "        \n",
    "  def test(self, test_users, batch_size = 100000):\n",
    "    '''\n",
    "    Returns [loss, accuracy] on the test set\n",
    "    '''\n",
    "    batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]\n",
    "    X_test = np.array([b[0] for b in batch_test])\n",
    "    y_test = np.array([b[1] for b in batch_test])\n",
    "    return self.m.evaluate(X_test, y_test)\n",
    "\n",
    "  def save_embeddings(self, file_name):\n",
    "    '''\n",
    "    Generates a csv file containg the vector embedding for each movie.\n",
    "    https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer\n",
    "    '''\n",
    "    inp = self.m.input                                          \n",
    "    outputs = [layer.output for layer in self.m.layers]          \n",
    "    functor = K.function([inp, K.learning_phase()], outputs )   \n",
    "\n",
    "    #append embeddings to vectors\n",
    "    vectors = []\n",
    "    for movie_id in range(self.movie_count):\n",
    "      movie = np.zeros((1, 1, self.movie_count))\n",
    "      movie[0][0][movie_id] = 1\n",
    "      layer_outs = functor([movie])\n",
    "      vector = [str(v) for v in layer_outs[0][0][0]]\n",
    "      vector = '|'.join(vector)\n",
    "      vectors.append([movie_id, vector])\n",
    "\n",
    "    #saves as a csv file\n",
    "    embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})\n",
    "    embeddings.to_csv(file_name, sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "history_length = 12 # kullanÄ±lan state sayÄ±sÄ±\n",
    "ra_length = 4 # Ã¶nerilen film listesi bÃ¼yÃ¼klÃ¼gÃ¼\n",
    "discount_factor = 0.99 # Gamma degeri  1 e yakÄ±n bir deger secilir\n",
    "actor_lr = 0.0001\n",
    "critic_lr = 0.001\n",
    "tau = 0.001 \n",
    "batch_size = 64\n",
    "nb_episodes = 100\n",
    "nb_rounds = 50\n",
    "filename_summary = 'summary.txt'\n",
    "alpha = 0.5\n",
    "gamma = 0.9 \n",
    "buffer_size = 1000000\n",
    "fixed_length = True\n",
    "movieData=MovieData(data)\n",
    "movieData.divideTrainAndTestSet()\n",
    "movieData.write_csv('train.csv', movieData.train)\n",
    "movieData.write_csv('test.csv', movieData.test)\n",
    "data = readFile('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = EmbeddingsInformation(movieData.user_train, pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp']))\n",
    "eg.train(nb_epochs=300)\n",
    "train_loss, train_accuracy = eg.test(movieData.user_train)\n",
    "print('Train set: Loss=%.4f ; Accuracy=%.4f%%' % (train_loss, train_accuracy * 100))\n",
    "test_loss, test_accuracy = eg.test(movieData.user_test)\n",
    "print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))\n",
    "eg.save_embeddings('embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_space_size: 1200\n",
      "action_space_size 400\n"
     ]
    }
   ],
   "source": [
    "embeddings = Embeddings(np.array([[np.float64(k) for k in e.split('|')]\n",
    "                   for e in  pd.read_csv('embeddings.csv', sep=';')['vectors']]))\n",
    "\n",
    "state_space_size = embeddings.size() * history_length\n",
    "print('state_space_size:',state_space_size)\n",
    "action_space_size = embeddings.size() * ra_length\n",
    "print('action_space_size',action_space_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    def __init__(self, data, embeddings, alpha, gamma, fixed_length):\n",
    "        self.embeddings = embeddings\n",
    "        self.embedded_data = pd.DataFrame()\n",
    "        self.embedded_data['state'] = [np.array([embeddings.get_embedding(item_id)\n",
    "                                                 for item_id in row['state']]) for _, row in data.iterrows()]\n",
    "        self.embedded_data['action'] = [np.array([embeddings.get_embedding(item_id)\n",
    "                                                  for item_id in row['action']]) for _, row in data.iterrows()]\n",
    "        self.embedded_data['reward'] = data['reward']\n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma \n",
    "        self.fixed_length = fixed_length\n",
    "        self.current_state = self.reset()\n",
    "        self.groups = self.get_groups()\n",
    "    def reset(self):\n",
    "        self.init_state = self.embedded_data['state'].sample(1).values[0]\n",
    "        return self.init_state\n",
    "    def step(self, actions):\n",
    "        simulated_rewards, cumulated_reward = self.simulate_rewards(self.current_state.reshape((1, -1)), actions.reshape((1, -1)))\n",
    "        for k in range(len(simulated_rewards)):\n",
    "            if simulated_rewards[k] > 0:\n",
    "                self.current_state = np.append(self.current_state, [actions[k]], axis=0)\n",
    "                if self.fixed_length:\n",
    "                    self.current_state = np.delete(self.current_state, 0, axis=0)\n",
    "        return cumulated_reward, self.current_state\n",
    "    def get_groups(self):\n",
    "        groups = []\n",
    "        for rewards, group in self.embedded_data.groupby(['reward']):\n",
    "            size = group.shape[0]\n",
    "            states = np.array(list(group['state'].values))\n",
    "            actions = np.array(list(group['action'].values))\n",
    "            groups.append({\n",
    "            'size': size, \n",
    "            'rewards': rewards, \n",
    "            'average state': (np.sum(states / np.linalg.norm(states, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)), # s_x^-\n",
    "            'average action': (np.sum(actions / np.linalg.norm(actions, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)) # a_x^-\n",
    "            })\n",
    "        return groups\n",
    "    def simulate_rewards(self, current_state, chosen_actions, reward_type='grouped cosine'):\n",
    "        def cosine_state_action(s_t, a_t, s_i, a_i):\n",
    "            cosine_state = np.dot(s_t, s_i.T) / (np.linalg.norm(s_t, 2) * np.linalg.norm(s_i, 2))\n",
    "            cosine_action = np.dot(a_t, a_i.T) / (np.linalg.norm(a_t, 2) * np.linalg.norm(a_i, 2))\n",
    "            return (self.alpha * cosine_state + (1 - self.alpha) * cosine_action).reshape((1,))\n",
    "        if reward_type == 'normal':\n",
    "            probabilities = [cosine_state_action(current_state, chosen_actions, row['state'], row['action'])\n",
    "                             for _, row in self.embedded_data.iterrows()]\n",
    "        elif reward_type == 'grouped average':\n",
    "            probabilities = np.array([g['size'] for g in self.groups]) *\\\n",
    "            [(self.alpha * (np.dot(current_state, g['average state'].T) / np.linalg.norm(current_state, 2))\\\n",
    "              + (1 - self.alpha) * (np.dot(chosen_actions, g['average action'].T) / np.linalg.norm(chosen_actions, 2)))\n",
    "             for g in self.groups]\n",
    "        elif reward_type == 'grouped cosine':\n",
    "            probabilities = [cosine_state_action(current_state, chosen_actions, g['average state'], g['average action'])\n",
    "                             for g in self.groups]\n",
    "        probabilities = np.array(probabilities) / sum(probabilities)\n",
    "        if reward_type == 'normal':\n",
    "            returned_rewards = self.embedded_data.iloc[np.argmax(probabilities)]['reward']\n",
    "        elif reward_type in ['grouped average', 'grouped cosine']:\n",
    "            returned_rewards = self.groups[np.argmax(probabilities)]['rewards']\n",
    "        def overall_reward(rewards, gamma):\n",
    "            return np.sum([gamma**k * reward for k, reward in enumerate(rewards)])\n",
    "        if reward_type in ['normal', 'grouped average']:\n",
    "            cumulated_reward = overall_reward(returned_rewards, self.gamma)\n",
    "        elif reward_type == 'grouped cosine':\n",
    "            cumulated_reward = np.sum([p * overall_reward(g['rewards'], self.gamma)\n",
    "                                       for p, g in zip(probabilities, self.groups)])\n",
    "        return returned_rewards, cumulated_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.buffer = []\n",
    "    def add(self, state, action, reward, n_state):\n",
    "        self.buffer.append([state, action, reward, n_state])\n",
    "        if len(self.buffer) > self.buffer_size:\n",
    "            self.buffer.pop(0)\n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "    def sample_batch(self, batch_size):\n",
    "        return random.sample(self.buffer, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_replay(replay_memory, batch_size, actor, critic, embeddings, ra_length, state_space_size, action_space_size, discount_factor):\n",
    "    samples = replay_memory.sample_batch(batch_size)\n",
    "    states = np.array([s[0] for s in samples])\n",
    "    actions = np.array([s[1] for s in samples])\n",
    "    rewards = np.array([s[2] for s in samples])\n",
    "    n_states = np.array([s[3] for s in samples]).reshape(-1, state_space_size)\n",
    "    n_actions = actor.get_recommendation_list(ra_length, states, embeddings, target=True).reshape(-1, action_space_size)\n",
    "    target_Q_value = critic.predict_target(n_states, n_actions, [ra_length] * batch_size)\n",
    "    expected_rewards = rewards + discount_factor * target_Q_value\n",
    "    critic_Q_value, critic_loss, _ = critic.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
    "    action_gradients = critic.get_action_gradients(states, n_actions, [ra_length] * batch_size)\n",
    "    actor.train(states, [ra_length] * batch_size, action_gradients)\n",
    "    critic.update_target_network()\n",
    "    actor.update_target_network()\n",
    "    return np.amax(critic_Q_value), critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrnsteinUhlenbeckNoise:\n",
    "  \n",
    "  def __init__(self, action_space_size, mu=0, theta=0.5, sigma=0.2):\n",
    "    self.action_space_size = action_space_size\n",
    "    self.mu = mu\n",
    "    self.theta = theta\n",
    "    self.sigma = sigma\n",
    "    self.state = np.ones(self.action_space_size) * self.mu\n",
    "\n",
    "  def get(self):\n",
    "    self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.rand(self.action_space_size)\n",
    "    return self.state\n",
    "\n",
    "def train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary):\n",
    "\n",
    "\n",
    "  # Set up summary operators\n",
    "  def build_summaries():\n",
    "    episode_reward = tf.Variable(0.)\n",
    "    tf.summary.scalar('reward', episode_reward)\n",
    "    episode_max_Q = tf.Variable(0.)\n",
    "    tf.summary.scalar('max_Q_value', episode_max_Q)\n",
    "    critic_loss = tf.Variable(0.)\n",
    "    tf.summary.scalar('critic_loss', critic_loss)\n",
    "\n",
    "    summary_vars = [episode_reward, episode_max_Q, critic_loss]\n",
    "    summary_ops = tf.summary.merge_all()\n",
    "    return summary_ops, summary_vars\n",
    "\n",
    "  summary_ops, summary_vars = build_summaries()\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(filename_summary, sess.graph)\n",
    "\n",
    "  # Initialize target network fâ€² and Qâ€²'\n",
    "  actor.init_target_network()\n",
    "  critic.init_target_network()\n",
    "  replay_memory = ReplayMemory(buffer_size) \n",
    "  replay = False\n",
    "\n",
    "  start_time = time.time()\n",
    "  for i_session in range(nb_episodes): \n",
    "    session_reward = 0\n",
    "    session_Q_value = 0\n",
    "    session_critic_loss = 0\n",
    "\n",
    "    states = environment.reset() # 'Initialize state s_0 from previous sessions'\n",
    "    \n",
    "    if (i_session + 1) % 10 == 0: # Update average parameters every 10 episodes\n",
    "      environment.groups = environment.get_groups()\n",
    "      \n",
    "    exploration_noise = OrnsteinUhlenbeckNoise(history_length * embeddings.size())\n",
    "\n",
    "    for t in range(nb_rounds): #for t = 1, T do\n",
    "     \n",
    "      # 'Select an action a_t = {a_t^1, ..., a_t^K} according to Algorithm 2'\n",
    "      actions = actor.get_recommendation_list(\n",
    "          ra_length,\n",
    "          states.reshape(1, -1), # TODO + exploration_noise.get().reshape(1, -1),\n",
    "          embeddings).reshape(ra_length, embeddings.size())\n",
    "\n",
    "      #  Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t'\n",
    "      rewards, next_states = environment.step(actions)\n",
    "\n",
    "      # 'Store transition (s_t, a_t, r_t, s_t+1)'\n",
    "      replay_memory.add(states.reshape(history_length * embeddings.size()),\n",
    "                        actions.reshape(ra_length * embeddings.size()),\n",
    "                        [rewards],\n",
    "                        next_states.reshape(history_length * embeddings.size()))\n",
    "\n",
    "      states = next_states # 'Set s_t = s_t+1'\n",
    "\n",
    "      session_reward += rewards\n",
    "      \n",
    "      \n",
    "      if replay_memory.size() >= batch_size: # Experience replay\n",
    "        replay = True\n",
    "        replay_Q_value, critic_loss = experience_replay(replay_memory, batch_size,\n",
    "          actor, critic, embeddings, ra_length, history_length * embeddings.size(),\n",
    "          ra_length * embeddings.size(), discount_factor)\n",
    "        session_Q_value += replay_Q_value\n",
    "        session_critic_loss += critic_loss\n",
    "\n",
    "      summary_str = sess.run(summary_ops,\n",
    "                             feed_dict={summary_vars[0]: session_reward,\n",
    "                                        summary_vars[1]: session_Q_value,\n",
    "                                        summary_vars[2]: session_critic_loss})\n",
    "      \n",
    "      writer.add_summary(summary_str, i_session)\n",
    "\n",
    "   \n",
    "    str_loss = str('Loss=%0.4f' % session_critic_loss)\n",
    "    print(('Episode %d/%d Reward=%d Time=%ds ' + (str_loss if replay else 'No replay')) % (i_session + 1, nb_episodes, session_reward, time.time() - start_time))\n",
    "    start_time = time.time()\n",
    "\n",
    "  writer.close()\n",
    "  tf.train.Saver().save(sess, 'models.h5', write_meta_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "embedded_data = pd.DataFrame()\n",
    "embedded_data['state'] = [np.array([embeddings.get_embedding(1) for item_id in row['state']]) for _, row in data.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149A1508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149A1508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149A1508>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149A1508>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149B9B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149B9B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149B9B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E2149B9B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E20E248B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E20E248B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E20E248B08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E20E248B08>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E206FE7248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E206FE7248>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E206FE7248>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E206FE7248>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E21244DB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E21244DB08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E21244DB08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E21244DB08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2029344C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2029344C8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2029344C8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2029344C8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E206FE7F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E206FE7F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E206FE7F48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GRUCell.call of <tensorflow.python.ops.rnn_cell_impl.GRUCell object at 0x000002E206FE7F48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x000002E2121A2088>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "Episode 1/100 Reward=539 Time=6s No replay\n",
      "Episode 2/100 Reward=539 Time=50s Loss=1507.8911\n",
      "Episode 3/100 Reward=539 Time=67s Loss=125.4557\n",
      "Episode 4/100 Reward=539 Time=64s Loss=75.6369\n",
      "Episode 5/100 Reward=539 Time=67s Loss=53.2248\n",
      "Episode 6/100 Reward=539 Time=69s Loss=52.1822\n",
      "Episode 7/100 Reward=539 Time=70s Loss=40.5407\n",
      "Episode 8/100 Reward=539 Time=66s Loss=29.1090\n",
      "Episode 9/100 Reward=539 Time=66s Loss=22.6005\n",
      "Episode 10/100 Reward=539 Time=70s Loss=17.0641\n",
      "Episode 11/100 Reward=539 Time=67s Loss=14.7949\n",
      "Episode 12/100 Reward=539 Time=68s Loss=12.2430\n",
      "Episode 13/100 Reward=539 Time=67s Loss=11.0041\n",
      "Episode 14/100 Reward=539 Time=66s Loss=9.3947\n",
      "Episode 15/100 Reward=539 Time=66s Loss=7.3789\n",
      "Episode 16/100 Reward=539 Time=80s Loss=7.3588\n",
      "Episode 17/100 Reward=539 Time=71s Loss=6.8769\n",
      "Episode 18/100 Reward=540 Time=71s Loss=5.9392\n",
      "Episode 19/100 Reward=540 Time=71s Loss=5.4083\n",
      "Episode 20/100 Reward=540 Time=71s Loss=4.2679\n",
      "Episode 21/100 Reward=540 Time=75s Loss=4.4401\n",
      "Episode 22/100 Reward=540 Time=91s Loss=4.6029\n",
      "Episode 23/100 Reward=540 Time=86s Loss=3.9164\n",
      "Episode 24/100 Reward=540 Time=90s Loss=3.7700\n",
      "Episode 25/100 Reward=540 Time=107s Loss=3.6445\n",
      "Episode 26/100 Reward=540 Time=103s Loss=3.8534\n",
      "Episode 27/100 Reward=540 Time=101s Loss=3.6147\n",
      "Episode 28/100 Reward=540 Time=104s Loss=3.3478\n",
      "Episode 29/100 Reward=540 Time=108s Loss=3.0093\n",
      "Episode 30/100 Reward=540 Time=109s Loss=2.8723\n",
      "Episode 31/100 Reward=540 Time=104s Loss=3.0956\n",
      "Episode 32/100 Reward=540 Time=110s Loss=2.9485\n",
      "Episode 33/100 Reward=540 Time=111s Loss=2.4976\n",
      "Episode 34/100 Reward=540 Time=102s Loss=2.5550\n",
      "Episode 35/100 Reward=540 Time=109s Loss=2.6238\n",
      "Episode 36/100 Reward=540 Time=101s Loss=2.2545\n",
      "Episode 37/100 Reward=540 Time=111s Loss=2.2957\n",
      "Episode 38/100 Reward=540 Time=103s Loss=2.4979\n",
      "Episode 39/100 Reward=540 Time=108s Loss=2.4561\n",
      "Episode 40/100 Reward=540 Time=104s Loss=2.0582\n",
      "Episode 41/100 Reward=540 Time=98s Loss=2.2963\n",
      "Episode 42/100 Reward=540 Time=104s Loss=1.9099\n",
      "Episode 43/100 Reward=540 Time=99s Loss=1.6944\n",
      "Episode 44/100 Reward=540 Time=83s Loss=1.7035\n",
      "Episode 45/100 Reward=540 Time=88s Loss=1.7018\n",
      "Episode 46/100 Reward=540 Time=84s Loss=1.5370\n",
      "Episode 47/100 Reward=540 Time=81s Loss=1.4903\n",
      "Episode 48/100 Reward=540 Time=79s Loss=1.3465\n",
      "Episode 49/100 Reward=540 Time=82s Loss=1.3410\n",
      "Episode 50/100 Reward=540 Time=87s Loss=1.5355\n",
      "Episode 51/100 Reward=540 Time=84s Loss=1.3746\n",
      "Episode 52/100 Reward=540 Time=82s Loss=1.2958\n",
      "Episode 53/100 Reward=540 Time=97s Loss=1.2655\n",
      "Episode 54/100 Reward=540 Time=107s Loss=1.2817\n",
      "Episode 55/100 Reward=540 Time=112s Loss=1.1727\n",
      "Episode 56/100 Reward=540 Time=111s Loss=1.1191\n",
      "Episode 57/100 Reward=540 Time=106s Loss=1.2624\n",
      "Episode 58/100 Reward=540 Time=106s Loss=1.2533\n",
      "Episode 59/100 Reward=540 Time=96s Loss=1.1466\n",
      "Episode 60/100 Reward=540 Time=101s Loss=1.4462\n",
      "Episode 61/100 Reward=540 Time=102s Loss=1.3649\n",
      "Episode 62/100 Reward=540 Time=101s Loss=1.2308\n",
      "Episode 63/100 Reward=540 Time=100s Loss=0.9895\n",
      "Episode 64/100 Reward=540 Time=101s Loss=1.2069\n",
      "Episode 65/100 Reward=540 Time=102s Loss=0.8356\n",
      "Episode 66/100 Reward=540 Time=100s Loss=0.7697\n",
      "Episode 67/100 Reward=540 Time=99s Loss=0.8451\n",
      "Episode 68/100 Reward=540 Time=99s Loss=1.1869\n",
      "Episode 69/100 Reward=540 Time=102s Loss=1.0729\n",
      "Episode 70/100 Reward=540 Time=101s Loss=0.7440\n",
      "Episode 71/100 Reward=540 Time=101s Loss=0.9917\n",
      "Episode 72/100 Reward=540 Time=103s Loss=1.0469\n",
      "Episode 73/100 Reward=540 Time=104s Loss=1.0479\n",
      "Episode 74/100 Reward=540 Time=104s Loss=0.8486\n",
      "Episode 75/100 Reward=540 Time=122s Loss=0.8304\n",
      "Episode 76/100 Reward=540 Time=106s Loss=0.7987\n",
      "Episode 77/100 Reward=540 Time=100s Loss=1.0916\n",
      "Episode 78/100 Reward=540 Time=106s Loss=0.7709\n",
      "Episode 79/100 Reward=540 Time=100s Loss=0.9647\n",
      "Episode 80/100 Reward=540 Time=108s Loss=0.9185\n",
      "Episode 81/100 Reward=540 Time=105s Loss=0.7876\n",
      "Episode 82/100 Reward=540 Time=99s Loss=0.8510\n",
      "Episode 83/100 Reward=540 Time=94s Loss=0.7516\n",
      "Episode 84/100 Reward=540 Time=97s Loss=0.8760\n",
      "Episode 85/100 Reward=540 Time=98s Loss=0.9418\n",
      "Episode 86/100 Reward=540 Time=92s Loss=0.8505\n",
      "Episode 87/100 Reward=540 Time=89s Loss=1.1811\n",
      "Episode 88/100 Reward=540 Time=74s Loss=0.8783\n",
      "Episode 89/100 Reward=540 Time=71s Loss=0.9682\n",
      "Episode 90/100 Reward=540 Time=71s Loss=0.7214\n",
      "Episode 91/100 Reward=540 Time=72s Loss=0.9126\n",
      "Episode 92/100 Reward=540 Time=73s Loss=0.9849\n",
      "Episode 93/100 Reward=540 Time=102s Loss=1.1422\n",
      "Episode 94/100 Reward=540 Time=128s Loss=0.8807\n",
      "Episode 95/100 Reward=540 Time=118s Loss=0.9190\n",
      "Episode 96/100 Reward=540 Time=117s Loss=1.1810\n",
      "Episode 97/100 Reward=540 Time=116s Loss=1.3258\n",
      "Episode 98/100 Reward=540 Time=108s Loss=1.2116\n",
      "Episode 99/100 Reward=540 Time=109s Loss=1.2651\n",
      "Episode 100/100 Reward=540 Time=117s Loss=1.1909\n"
     ]
    }
   ],
   "source": [
    "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
    "critic = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
    "train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_embeddings = {}\n",
    "for i, item in enumerate(embeddings.get_embedding_vector()):\n",
    "    str_item = str(item)\n",
    "    assert(str_item not in dict_embeddings)\n",
    "    dict_embeddings[str_item] = i\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_to_items(state, actor, ra_length, embeddings, dict_embeddings, target=False):\n",
    "  return [dict_embeddings[str(action)]\n",
    "          for action in actor.get_recommendation_list(ra_length, np.array(state).reshape(1, -1), embeddings, target).reshape(ra_length, embeddings.size())]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = pd.read_csv('testdata.csv', sep=';')\n",
    "testMovieList=findList(testdata,194)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findList(testdata,userIdInfo):\n",
    "    movieList=[]\n",
    "    indexV=int(testdata[testdata['userId']==userIdInfo].state.index.values[0])\n",
    "    listOfItem= testdata[testdata['userId']==userIdInfo].state[indexV].split('|')\n",
    "    for i in range(len(listOfItem)-1):\n",
    "        movieList.append(listOfItem[i].split('&')[0])\n",
    "    return movieList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_RL(actor, train_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
    "    hits=0\n",
    "    total=0\n",
    "    for i in range(len(train_df)):\n",
    "        userId = train_df[i]['userId'][0]  \n",
    "        history_sample =list(train_df[i].sample(history_length)['itemId'])\n",
    "        recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
    "        testMovieList=findList(testdata,userId)\n",
    "        for item in recommendation:\n",
    "            for movie in testMovieList:\n",
    "                if(int(item) == int(movie)):\n",
    "                    hits+=1\n",
    "        total+=1 \n",
    "    return hits/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "hitrate=test_RL(actor, movieData.train, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042440318302387266"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hitrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_actor(actor, test_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
    "  ratings = []\n",
    "  unknown = 0\n",
    "  random_seen = []\n",
    "  for _ in range(nb_rounds):\n",
    "    for i in range(len(test_df)):\n",
    "      history_sample = list(test_df[i].sample(history_length)['itemId'])\n",
    "      recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
    "        \n",
    "      for item in recommendation:\n",
    "        l = list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])\n",
    "        assert(len(l) < 2)\n",
    "        if len(l) == 0:\n",
    "          unknown += 1\n",
    "        else:\n",
    "          ratings.append(l[0])\n",
    "      for item in history_sample:\n",
    "        random_seen.append(list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])[0])\n",
    "\n",
    "  return ratings, unknown, random_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.0% unknown\n"
     ]
    }
   ],
   "source": [
    "ratings, unknown, random_seen = test_actor(actor, movieData.train, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=10)\n",
    "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions ; Mean = 3.8605')"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings)\n",
    "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM0AAAEICAYAAAD87nDaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAUBElEQVR4nO3df7BcZX3H8feHEJRCEDCAQII3YqpALAFSiEN1EChEogYdaAOWRItFbagybUcC1vJD6OBMFWQEWpEUomiIIjUCGtMYtToIJPwOISWGyK9AEpNAAgoT+PaP51k9rLu5++y9yZ5kPq+ZM/fs85xz9tmb+9lz9snO+SoiMLPO7dDrAZhtaxwas0IOjVkhh8askENjVsihMSvk0HRA0jGSnuz1OKwettnQSFoh6beSNkp6RtL1knbt9bi2JEl9kkLSPU3twyW9LGlFj4ZWTNI5kpZLel7S05Iul7RjB/tdkH8Hx1faFue/g8aySdL3K/3HSronP9dySWc1HfN0Sb+W9IKk/5a05+bGsM2GJnt/ROwKjAUOA87r8Xi2ll0kjak8Ph14rFeD6dL3gcMjYjdgDHAo8KnN7SDpQOAUYGW1PSIOiYhd89/CMOBx4Nt5n6HALcB/Am8A/hr4kqRDc/8hue8MYB/gReDqzY1jWw8NABHxDDCXFB4AJE2UdG9+d3lC0oWVvsY79lRJj0taI+mzlf6d85lrnaSHgT+vPp+kgyT9RNL6/C73gUrf9ZKulvSD/K73C0lvknRFPt4jkg5r91ok3Sppej8v+evA1MrjKcDMpuPsJ+lmSaslPSbpU5W+IyXdkce/UtJXJO1U6Q9Jn5D0aB7zVZLUz5iKRMSvImJ94ymBV4G39rPbV4BzgZc3s827gb2Bm/PjPYHdgK9HcjewBDg4938Y+H5E/CwiNgKfAz4kadjmBr9NLsAK4Pi8PgJ4EPhypf8Y4B2kN4Y/A54FTs59fUAA1wI7k97lXgIOyv2XAf+bf+EjgYeAJ3PfUGAZcD6wE3AssAF4W+6/HlgDHAG8Hvgx6SwwBRgCXAIs6PI1N8bdBzyRj3cQsBQ4HliRt9sBWAT8ax7jW4DlwIm5/whgPLBjPtYS4JzK8wRwK7A7cACwGpjQZkynA+s3sxywmddzOvB8fr7VwKGb2fZU4HvN//YttpsBXN/U9k1gWv59vRNYBYzMfd8Dzm3afiNwRNux9PqPf4Ch2Zj/YAOYD+y+me2vAC5v+uMbUem/C5ic15dX/0iAsyqheRfwDLBDpf9bwIWV0Fxb6fsHYEnl8TuA9QMMzY7A/wAnkgL+2abQHAU83rTvecB/tTnuOcAtTaH5i8rj2cD0LfhvORr4PPCmNv27Ao8Coyr/9n8UGuBPcgiPaWp/P+lNc1Ne/q7SNx/4RNP2TzUfo7ps65dnJ0fEMNJZ5e3A8EaHpKMkLciXJ88Bn6j2Z89U1l8k/eMA7Ed6J2/4dWV9P+CJiHi1qX//yuNnK+u/bfF4MCYsZgIfAU4DvtHU92Zgv3z5tV7SetKZcR8ASX+aLwOfkfQ88G90/rsZdBHxKLCY9p8lLiJdXvX3ue1DwFrgp40GSW8HbiKd6XcCDgE+I2li3mQj6fKtajfSm3FL23poAIiIn5Le4f+90vxNYA7pNPwG4D9I186dWEm6LGs4oLL+NDBS0g5N/U8VDnugbgYmAssj4tdNfU8Aj0XE7pVlWESclPuvAR4BRkf6IH4+nf9uXkPSh5tmrpqXA/o/CpDOnge26TsO+FQO+TOkf5vZks5t2m4qMDPy6SIbAyyNiLkR8WpELAVuA96b+xeTLs8br+ctwOuA/2s30O0iNNkVwF9KakwGDAPWRsTvJB1Jun7u1GzgPEl7SBpBusRquBN4gfRuNVTSMaTT/6wBvwIgTzBc2N92EfEC6fPUx1p03wU8L+ncPKkxRNIYSY0JjWGky5iN+Z34k92ONyJujDxz1WZ5vNV+kj4mae+8fjDp8nF+m6c5jvTHPzYvTwMfB66qHG8E8B7ghqZ97wVG52ln5Rm49wH35/4bgfdLepekXYCLge9GxPZ9pgGIiNWkS5bP5aa/By6WtIH0gXh2weEuIl1yPQb8iDRb1Xiel4EPkN6p1pAuKaZExCMDfQ3ZSOAXnWwYEQsj4lct2l8hBXks6TWsAb5GmnIF+GfSm8gG0mTITQMfdrGjgQclvQDcnpfzG515VvLDABHxm4h4prEArwDrIs12NZwB3NH8+8iP/xa4kvRG8VPSWfq63L+YdOl+I2mCYBjpb6ctvfZMZr2U3y2/HRHv7PVYrD2HxqzQdnN5Zra1ODRmhRwas0L9fqu0roYPHx59fX29HoZtpxYtWrQmIvZq1bfNhqavr4+FCxf2ehi2nZLU/B/Gv+fLM7NCDo1ZIYfGrJBDY1bIoTEr5NCYFXJozAo5NGaFHBqzQtvsNwKsvvqm39bVfisum9j/RjXgM41ZIYfGrJBDY1bIoTEr5NCYFXJozAo5NGaFHBqzQg6NWSGHxqyQQ2NWyKExK+TQmBVyaMwK9RsaSa+XdJek+3PNkIty+yhJd+YKwDc1qgNLel1+vCz391WOdV5uXyrpxEr7hNy2rIPKxmY91cmZ5iXg2Ig4lFQkaIKk8cAXSIVfRwPrgDPz9meSCu68Fbg8b9eodjWZVPNwAnB1rtA1hFTR6r2kMtWn5W3Naqnf0ETSqDg1NC9BKl33ndx+A3ByXp/EH0q4fQc4LtegnwTMioiXcsHRZcCReVkWEctzlbFZeVuzWuroM00+I9xHKq82D/gVqaz3przJk/yhuvH+5MrIuf854I3V9qZ92rW3GsdZkhZKWrh69epOhm426DoKTUS8EhFjgRGkM8NBrTbLP1tVCY4u2luN46sRMS4ixu21V8sbupttcUWzZxGxHvgJMB7YXVLjHgMjSBV3IZ0pRgLk/jeQarv/vr1pn3btZrXUyezZXpJ2z+s7A8cDS4AFwCl5s6nA9/L6nPyY3P/jXNd9DjA5z66NAkaTSnffTSpZPSrPwE3O25rVUid3o9kXuCHPcu0AzI6IWyU9DMySdAmpVvt1efvrgK9LWkY6w0yGVHpa0mzgYWATMC2X7kbS2cBcYAgwI5epNqulfkMTEQ8Ah7VoX076fNPc/jvg1DbHuhS4tEV7o468We35GwFmhRwas0IOjVkhh8askENjVsihMSvk0JgVcmjMCjk0ZoUcGrNCDo1ZIYfGrJBDY1bIoTEr5NCYFXJozAo5NGaFHBqzQg6NWSGHxqyQQ2NWyKExK9TJzQJHSlogaUkutfHp3H6hpKck3ZeXkyr7FJXUaFe2w6yOOjnTbAL+KSIOIt2OdlqlFMblETE2L7dD1yU12pXtMKudTm4WuBJYmdc3SFpCm7v6Z78vqQE8lu+02bip4LJ8k0EkzQIm5eMdC5yet7kBuBC4pvzlWDt902/rar8Vl00c5JFs+4o+0+SqZocBd+amsyU9IGmGpD1yW2lJjTfSvmyHWe10HBpJuwI3A+dExPOkM8GBpOpoK4EvNjZtsfuglNpwfRqrg06LOg0lBebGiPguQEQ8m+vWvApcyx8uwUpLaqyhfdmO13B9GquDTmbPRKoEsCQivlRp37ey2QeBh/J6UUmNXIajXdkOs9rppNTG0cAZwIO5hCDA+aTZr7GkS6kVwMeh65Ia59K6bIdZ7XQye/ZzWn/uaFsao7SkRruyHWZ15G8EmBVyaMwKOTRmhRwas0IOjVkhh8askENjVsihMSvk0JgVcmjMCjk0ZoUcGrNCDo1ZIYfGrJBDY1bIoTEr5NCYFXJozAo5NGaFHBqzQg6NWSGHxqyQQ2NWaCD1afaUNC/XlJnXuAG6kitzDZoHJB1eOdbUvP2jkqZW2o+Q9GDe58p8V0+zWhpIfZrpwPxcU2Z+fgyp/szovJxFLpkhaU/gAuAo0o0BL6hUGrgmb9vYb8LAX5rZltFvaCJiZUTck9c3AI36NJNItWTIP0/O65OAmZH8knRz832BE4F5EbE2ItYB84AJuW+3iLgj39d5ZuVYZrUzkPo0++SCT43CT3vnzUrr0+yf15vbWz2/S21Yzw2kPk3bTVu0DUp9GpfasDrouj4N8Gyj3Eb+uSq3l9aneTKvN7eb1VLX9WlIdWgaM2DVmjJzgCl5Fm088Fy+fJsLnCBpjzwBcAIwN/dtkDQ+P9cUXJ/Gamwg9WkuA2ZLOhN4HDg1990OnAQsA14EPgoQEWslfZ5U3Ang4ohYm9c/CVwP7Az8IC9mtTSQ+jQAx7XYPoBpbY41A5jRon0hMKa/sZjVgb8RYFbIoTEr5NCYFXJozAo5NGaFHBqzQg6NWSGHxqyQQ2NWyKExK+TQmBVyaMwKOTRmhRwas0IOjVkhh8askENjVsihMSvk0JgV6uTGGma11jf9tq72W3HZxK7285nGrJBDY1aok5sFzpC0StJDlbYLJT0l6b68nFTpOy+XzFgq6cRK+4TctkzS9Er7KEl35vIbN0naaTBfoNlg6+RMcz2tS19cHhFj83I7QC7BMRk4JO9ztaQhkoYAV5HKcBwMnJa3BfhCPtZoYB1w5kBekNmW1kmpjZ8Ba/vbLpsEzIqIlyLiMdJdNo/My7KIWB4RLwOzgEn5NrTHAt/J+1dLdpjV0kA+05ydK53NqBRnKi2z8UZgfURsampvyaU2rA66Dc01wIHAWGAl8MXcvsXKbIBLbVg9dPX/NBHxbGNd0rXArflhu3IatGlfQ6qUtmM+27jMhtVeV2eaRl2a7INAY2ZtDjBZ0uskjSLVz7yLVClgdJ4p24k0WTAn3yx9AXBK3r9assOslvo900j6FnAMMFzSk6Ris8dIGku6lFoBfBwgIhZLmg08TCpwOy0iXsnHOZtUo2YIMCMiFuenOBeYJekS4F5SLRyz2uqk1MZpLZrb/mFHxKXApS3abyfVrmluX06aXTPbJvgbAWaFHBqzQg6NWSGHxqyQQ2NWyKExK+TQmBVyaMwKOTRmhRwas0IOjVkhh8askENjVsihMSvk0JgVcmjMCjk0ZoUcGrNCDo1ZIYfGrJBDY1bIoTEr5EpoA7S1q3BZ73Vbn2ZPSfNyTZl5jRugK7ky16B5QNLhlX2m5u0flTS10n6EpAfzPlfmSgJmtdVtfZrpwPxcU2Z+fgyp/szovJxFulE6kvYk3ZnzKNKNAS+oVBq4Jm/b2K9VLRyz2ui2Ps0kUi0ZeG1NmUnAzEh+Sbq5+b7AicC8iFgbEeuAecCE3LdbRNyR7+s8E9ensZrrdiJgn4hYCZB/7p3bS+vT7J/Xm9tbcn0aq4PBnj1zfRrb7nUbmmcb5Tbyz1W5vV19ms21j2jRblZb3YZmDqmWDLy2pswcYEqeRRsPPJcv3+YCJ0jaI08AnADMzX0bJI3Ps2ZTcH0aq7lu69NcBsyWdCbwOHBq3vx24CRSgdoXgY8CRMRaSZ8nFXcCuDgiGpMLnyTN0O0M/CAvZrXVbX0agONabBvAtDbHmQHMaNG+EBjT3zjM6sJfozEr5NCYFXJozAo5NGaFHBqzQg6NWSGHxqyQQ2NWyKExK+TQmBVyaMwKOTRmhRwas0IOjVkhh8askENjVsihMSvk0JgVcmjMCjk0ZoUcGrNCDo1ZoQHVp5G0AtgAvAJsiohxuULATUAfsAL4q4hYl28G+GXSfdFeBD4SEffk40wF/iUf9pKIuIEB6KZmjOvFWKcG40zznogYGxHj8uPBLMNhVjtb4vJsUMpwbIFxmQ2KgYYmgB9JWiTprNw2WGU4/ohLbVgdDLTm5tER8bSkvYF5kh7ZzLYDLrcREV8Fvgowbty4tiU5zLakAZ1pIuLp/HMVcAvpM8lgleEwq6WuQyNpF0nDGuuk8hkPMUhlOLodl9mWNpDLs32AW3Ix5h2Bb0bEDyXdzeCV4TCrna5DExHLgUNbtP+GQSrDYVZH/kaAWSGHxqyQQ2NWyKExK+TQmBVyaMwKOTRmhRwas0IOjVkhh8askENjVsihMSvk0JgVcmjMCjk0ZoUcGrNCDo1ZIYfGrJBDY1bIoTEr5NCYFXJozAo5NGaFahMaSRMkLZW0TNL0/vcw641ahEbSEOAqUg2bg4HTJB3c21GZtVaL0JBunL4sIpZHxMvALFI9G7PaUbpbbI8HIZ0CTIiIj+XHZwBHRcTZTdudRaqiBvA2YGmbQw4H1myh4ZaoyzigPmOpyzhg82N5c0Ts1apjoPVpBktHNWqq9Wk2ezBpYaWcYc/UZRxQn7HUZRzQ/VjqcnnmGjW2zahLaO4GRksaJWknYDKpno1Z7dTi8iwiNkk6m1TMaQgwIyIWD+CQ/V7CbSV1GQfUZyx1GQd0OZZaTASYbUvqcnlmts1waMwKbVehkTRD0ipJD/V4HCMlLZC0RNJiSZ/u0TheL+kuSffncVzUi3E0jWmIpHsl3drjcayQ9KCk+yQtLNp3e/pMI+ndwEZgZkSM6eE49gX2jYh7cgXsRcDJEfHwVh6HgF0iYqOkocDPgU9HxC+35jiaxvSPwDhgt4h4Xw/HsQIYFxHF/9G6XZ1pIuJnQM8rQ0fEyoi4J69vAJYA+/dgHBERG/PDoXnp2bukpBHAROBrvRrDYNiuQlNHkvqAw4A7e/T8QyTdB6wC5kVET8aRXQF8Bni1h2NoCOBHkhblr2d1zKHZgiTtCtwMnBMRz/diDBHxSkSMJX3L4khJPblslfQ+YFVELOrF87dwdEQcTvpm/bR8ad8Rh2YLyZ8hbgZujIjv9no8EbEe+AkwoUdDOBr4QP4sMQs4VtI3ejQWIuLp/HMVcAvpm/YdcWi2gPwB/DpgSUR8qYfj2EvS7nl9Z+B44JFejCUizouIERHRR/qa1I8j4m96MRZJu+QJGiTtApwAdDzjul2FRtK3gDuAt0l6UtKZPRrK0cAZpHfT+/JyUg/GsS+wQNIDpO/3zYuInk711sQ+wM8l3Q/cBdwWET/sdOftasrZbGvYrs40ZluDQ2NWyKExK+TQmBVyaMwKOTRmhRwas0L/D9L+4GVgntBIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_seen)\n",
    "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.2% unknown\n"
     ]
    }
   ],
   "source": [
    "ratings, unknown, random_seen = test_actor(actor, movieData.train, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=10)\n",
    "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Predictions ; Mean = 3.8665')"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(ratings)\n",
    "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(random_seen)\n",
    "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
